import React, { useState } from 'react'
import styled from 'styled-components'

import Section from './components/Section'
import NavBar from './components/NavBar'
import ComparisonSlider from './components/ComparisonSlider'
import ComparisonToggle from './components/ComparisonToggle'

import overview from '/overview.svg'
import paper from '/download/two-hist.pdf'
import slides from '/download/two-hist-slides.pdf'

const bibtex = `@thesis{Tu2024,
  author  = {Chia-Ming Tu, Shao-Yi Chien, Bing-Yu Chen},
  title   = {Two-history Approach of Spatiotemporal Filtering for Monte Carlo Rendering: Spatiotemporal Variance-Guided Filtering as Example},
  school  = {National Taiwan University},
  year    = {2024},
  type    = {Master's thesis}
}
`

function App() {

  let sections = [
    (
      <Section title="Abstract">
        <p>
        Spatio-temporal reusing samples is critical to reducing noise for realtime ray-tracing.
        Existing methods usually assume inputs are generated by constant sample-per-pixel and use exponential moving averages to aggregate colors for temporal reuse.
        However, when sample-per-pixel vary, these approaches fail to effectively utilize colors generated by high sample counts.
        In this study, we proposed a novel method termed the "Two-history Approach" to augment existing spatio-temporal denoisers, enhancing their ability to handle inputs with variable sample count.
        We adapt the SVGF algorithm using our approach and evaluate its performance with a simple foveated rendering pipeline.
        </p>
      </Section>
    ),
    (
      <Section title="Resources">
        <Link href={paper} target="_blank">
          <Icon src="pdf_icon.svg"></Icon>Paper (pdf)
        </Link>
        <br/>
        <Link href={slides} target="_blank">
          <Icon src="pdf_icon.svg"></Icon>Slides (pdf)
        </Link>
        <br/>
        <Link href="https://github.com/jd3main/Falcor/tree/thesis_TwoHistorySVGF" target="_blank">
          <Icon src="github_icon.svg"></Icon>Source Code (GitHub)
        </Link>
        <h3>Citation</h3>
        <p>
        Chia-Ming Tu,
        "Two-history Approach of Spatiotemporal Filtering for Monte Carlo Rendering: Spatiotemporal Variance-Guided Filtering as Example", 2024.
        </p>
        <h3>Bibtex</h3>
        <CenterText>
          <Code>
          {bibtex}
          </Code>
        </CenterText>
      </Section>
    ),
    (
      <Section title="Results">
        <h3>Original vs Two-history</h3>

        <p>Inside the circle is the foveal area.</p>
        <ComparisonToggle
          disabledSrc="/images/SunTemple_243_Unweighted.png"
          enabledSrc="/images/SunTemple_243_TwoHist.png"
          disabledLabel="Original"
          enabledLabel="Two-history"
          style={{ margin:'auto' }}>
        </ComparisonToggle>

        {/* <ComparisonSlider
          leftSrc="/images/SunTemple_243_Unweighted.png"
          rightSrc="/images/SunTemple_243_TwoHist.png"
          leftText="Original"
          rightText="Two-history"
          width="100%">
        </ComparisonSlider> */}
        <br/>
        <CenterText>
          <iframe style={{width:"640px", height:"360px", maxWidth:"100%"}} src="https://www.youtube.com/embed/OZGGhqCfqrs?si=6EYEwysVYuN7kpUp" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen></iframe>
        </CenterText>
        <h3>Sample-count-weighted vs Two-history</h3>
        <p>We avoid temporal bias difference of sample-count-weighted method</p>
        <CenterText>
          <iframe style={{width:"640px", height:"360px", maxWidth:"100%"}} src="https://www.youtube.com/embed/tLePHK9ir2c?si=-bXfr27RugMfOzdw" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen></iframe>
        </CenterText>
      </Section>
    ),
    (
      <Section title="References">
        <p>
          [1] C. Schied, A. Kaplanyan, C. Wyman, A. Patney, C. R. A. Chaitanya, J. Burgess, S. Liu, C. Dachsbacher, A. Lefohn, and M. Salvi, “Spatiotemporal variance-guided filtering: real-time reconstruction for path-traced global illumination,” in Proceedings of High Performance Graphics, ser. HPG ’17. New York, NY, USA: Association for Computing Machinery, 2017.<br/>
          [2] H. Dammertz, D. Sewtz, J. Hanika, and H. P. A. Lensch, “Edge-avoiding ` Atrous wavelet transform for fast global illumination filtering,” in Proceedings of the Conference on High Performance Graphics, ser. HPG ’10. Goslar, DEU: Eurographics Association, 2010, p. 67–75.<br/>
          [3] C. Schied, C. Peters, and C. Dachsbacher, “Gradient estimation for real-time adaptive temporal filtering,” Proc. ACM Comput. Graph. Interact. Tech., vol. 1, no. 2, aug 2018.<br/>
          [4] B. Bitterli, C. Wyman, M. Pharr, P. Shirley, A. Lefohn, and W. Jarosz, “Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting,” ACM Trans. Graph., vol. 39, no. 4, aug 2020.<br/>
          [5] G. Boiss´ e, “World-space spatiotemporal reservoir reuse for ray-traced global illumination,” in SIGGRAPH Asia 2021 Technical Communications, ser. SA ’21. New York, NY, USA: Association for Computing Machinery, 2021. https://doi.org/10.1145/3478512.3488613<br/>
          [6] Y. Ouyang, S. Liu, M. Kettunen, M. Pharr, and J. Pantaleoni, “Restir gi: Path  resampling for real-time path tracing,” Computer Graphics Forum, vol. 40, no. 8, pp. 17–29, 2021.<br/>
          [7] D. Lin, C. Wyman, and C. Yuksel, “Fast volume rendering with spatiotemporal reservoir resampling,” ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2021), vol. 40, no. 6, pp. 278:1–278:18, 12 2021. http://doi.acm.org/10.1145/3478513.3480499<br/>
          [8] D. Lin, M. Kettunen, B. Bitterli, J. Pantaleoni, C. Yuksel, and C. Wyman, “Generalized resampled importance sampling: foundations of restir,” ACM Trans. Graph., vol. 41, no. 4, jul 2022.<br/>
          [9] A. Kuznetsov, N. K. Kalantari, and R. Ramamoorthi, “Deep adaptive sampling for low sample count rendering,” Computer Graphics Forum, vol. 37, pp. 35–44, 2018.<br/>
          [10] C. R. A. Chaitanya, A. S. Kaplanyan, C. Schied, M. Salvi, A. Lefohn, D. Nowrouzezahrai, and T. Aila, “Interactive reconstruction of monte carlo image sequences using a recurrent denoising autoencoder,” ACM Trans. Graph., vol. 36, no. 4, jul 2017. https://doi.org/10.1145/3072959.3073601<br/>
          [11] J. Hasselgren, J. Munkberg, M. Salvi, A. Patney, and A. Lefohn, “Neural temporal adaptive sampling and denoising,” Computer Graphics Forum, vol. 39, no. 2, pp. 147–155, 2020. https://onlinelibrary.wiley.com/doi/abs/10. 1111/cgf.13919<br/>
          [12] M. Weier, T. Roth, E. Kruijff, A. Hinkenjann, A. P´erard-Gayot, P. Slusallek, and Y. Li, “Foveated real-time ray tracing for head-mounted displays,” Comput. Graph. Forum, vol. 35, no. 7, p. 289–298, oct 2016.<br/>
          [13] Y. Kim, Y. Ko, and I. Ihm, “Selective foveated ray tracing for head-mounted displays,” in 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2021, pp. 413–421.<br/>
          [14] B. Jin, I. Ihm, B. Chang, C. Park, W. Lee, and S. Jung, “Selective and adaptive supersampling for real-time ray tracing,” in Proceedings of the Conference on High Performance Graphics 2009, ser. HPG ’09. New York, NY, USA: Association for Computing Machinery, 2009, p. 117–125.<br/>
          [15] L. Wang, X. Shi, and Y. Liu, “Foveated rendering: A state-of-the-art survey,” Computational Visual Media, vol. 9, no. 2, pp. 195–228, Jun 2023.<br/>
          [16] C. R. A. Chaitanya, A. S. Kaplanyan, C. Schied, M. Salvi, A. Lefohn, D. Nowrouzezahrai, and T. Aila, “Interactive reconstruction of monte carlo image sequences using a recurrent denoising autoencoder,” ACM Trans. Graph., vol. 36, no. 4, jul 2017. https://doi.org/10.1145/3072959.3073601<br/>
          [17] J. H. Mueller, T. Neff, P. Voglreiter, M. Steinberger, and D. Schmalstieg, “Temporally adaptive shading reuse for real-time rendering and virtual reality,” vol. 40, no. 2, apr 2021. https://doi.org/10.1145/3446790<br/>
          [18] L. Yang, D. Nehab, P. V. Sander, P. Sitthi-amorn, J. Lawrence, and H. Hoppe, “Amortized supersampling,” ACM Trans. Graph., vol. 28, no. 5, p. 1–12, dec 2009. https://doi.org/10.1145/1618452.1618481<br/>
          [19] B. Karis, “High-qality temporal supersampling,” 2014.<br/>
          [20] Z. Wang, A. Bovik, H. Sheikh, and E. Simoncelli, “Image quality assessment: from error visibility to structural similarity,” IEEE Transactions on Image Processing, vol. 13, no. 4, pp. 600–612, 2004.<br/>
          [21] S. Kallweit, P. Clarberg, C. Kolb, T. Davidoviˇc, K.-H. Yao, T. Foley, Y. He, L. Wu, L. Chen, T. Akenine-M¨oller, C. Wyman, C. Crassin, and N. Benty, “The Falcor rendering framework,” 8 2022. https: //github.com/NVIDIAGameWorks/Falcor<br/>
          [22] A. Lumberyard, “Amazon lumberyard bistro, open research co  tent archive (orca),” July 2017. http://developer.nvidia.com/orca/ amazon-lumberyard-bistro<br/>
          [23] K. A. Nicholas Hull and N. Benty, “Nvidia emerald square, open research content archive (orca),” July 2017. http://developer.nvidia.com/orca/ nvidia-emerald-square<br/>
          [24] E. Games, “Unreal engine sun temple, open research content archive (orca),” October 2017. http://developer.nvidia.com/orca/epic-games-sun-temple<br/>
          [25] M. Winkelmann, “Zero-day, open research content archive (orca),” November 2019. https://developer.nvidia.com/orca/beeple-zero-day<br/>
          [26] B. Bitterli, “Rendering resources,” 2016, https://benedikt-bitterli.me/ resources/.<br/>
        </p>
      </Section>
    ),
  ]

  /* set keys */
  sections = sections.map((section, index) => {
    return React.cloneElement(section, { key: index })
  });


  let navEntries = sections.map((section) => {
    return { title: section.props.title, targetId: section.props.title };
  });
  navEntries = [{ title:"Top", targetId:"Top" }].concat(navEntries);

  return (
    <>
      <NavBar entries={navEntries} zindex={999}></NavBar>
      <div style={{margin: "5em 1em"}}>
        <MainTitle id="Top">
          Two-history Approach of Spatiotemporal Filtering for Monte Carlo Rendering: Spatiotemporal Variance-Guided Filtering as Example
        </MainTitle>
        <div style={{margin: "2em"}}>
          <AuthorText>Chia-Ming Tu</AuthorText>
          <AuthorText>Advisor: Shao-Yi Chien and Bing-Yu Chen</AuthorText>
        </div>
        <CenterText>
          <img src={overview} alt="overview" style={{maxWidth: "100%", margin: "1em"}}></img>
        </CenterText>
      </div>
      {sections}
    </>
  )
}

const CenterText = styled.div`
  text-align: center;
  margin-left: auto;
  margin-right: auto;
`

const Link = styled.a`
  display: inline-block;
  margin: 0.5em 0em;
  color: #666;
  font-size: 1.2em;

  &:hover {
    color: #7af;
  }
  
  &:visited {
  }
`

const Code = styled.pre`
  display: block;
  font-family: "Source Code Pro", monospace;
  text-align: left;
  background-color: #555;
  color: white;
  overflow-x: auto;
  padding: 1em;
`

const MainTitle = styled.h1`
  text-align: center;
  margin: 5em 0 1em 0;
`

const AuthorText = styled.p`
  text-align: center;
  font-style: italic;
  font-size: 1.2em;
  margin: 0;
`

const Icon = styled.img`
  width: 1.2em;
  margin: 0 0.5em;
  vertical-align: middle;
`

export default App
